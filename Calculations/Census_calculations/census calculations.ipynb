{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the 2022 SAM boundaries as geodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/SMALL_AREA_2022_Genralised_20m_view_-4176251332041431098.geojson', driver='GeoJSON')\n",
    "\n",
    "df = gpd.GeoDataFrame(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep Dublin SAM boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SA_NUTS3_NAME']=='Dublin'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read our SAM 2022 statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv('data/SAPS_2022_Small_Area_270923 (1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each boundary, find the corresponding statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for ii, row in df.iterrows():\n",
    "    tmp = stats[stats['GUID']==row['SA_GUID_2022']]\n",
    "    if len(tmp)==1:\n",
    "        ids.append(tmp.index[0])\n",
    "    else:\n",
    "        print('error')\n",
    "        break\n",
    "\n",
    "df['SAP_ID']=ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in the stats associated with this ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "statlist = [\n",
    "'T1_1AGETT',\n",
    "'T11_1_FW',\n",
    "'T11_1_BIW',\n",
    "'T11_1_BUW',\n",
    "'T11_1_TDLW',\n",
    "'T11_1_MW',\n",
    "'T11_1_CDW',\n",
    "'T11_1_CPW',\n",
    "'T11_1_VW',\n",
    "'T11_1_OTHW',\n",
    "'T11_1_WMFHW',\n",
    "'T11_1_NSW',\n",
    "'T11_1_TW',\n",
    "'T11_1_FSCCC',\n",
    "'T11_1_BISCCC',\n",
    "'T11_1_BUSCCC',\n",
    "'T11_1_TDLSCCC',\n",
    "'T11_1_MSCCC',\n",
    "'T11_1_CDSCCC',\n",
    "'T11_1_CPSCCC',\n",
    "'T11_1_VSCCC',\n",
    "'T11_1_OTHSCCC',\n",
    "'T11_1_WMFHSCCC',\n",
    "'T11_1_NSSCCC',\n",
    "'T11_1_TSCCC',\n",
    "'T11_1_FT',\n",
    "'T11_1_BIT',\n",
    "'T11_1_BUT',\n",
    "'T11_1_TDLT',\n",
    "'T11_1_MT',\n",
    "'T11_1_CDT',\n",
    "'T11_1_CPT',\n",
    "'T11_1_VT',\n",
    "'T11_1_OTHT',\n",
    "'T11_1_WMFHT',\n",
    "'T11_1_NST',]\n",
    "\n",
    "for stat in statlist:\n",
    "    df[stat]=df['SAP_ID'].apply(lambda x: stats[stat].iloc[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does population add up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['T1_1AGETT'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Finally rename columns based on glossary gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = pd.read_excel('data/Glossary_Saps_2022_270923.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = []\n",
    "for column in df.columns:\n",
    "    tmp = gl[gl['Column Names']==column]\n",
    "    if len(tmp)==1:\n",
    "        cc.append(tmp['Description of Field'].values[0])\n",
    "    else:\n",
    "  \n",
    "        cc.append(column)\n",
    "\n",
    "df.columns=cc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('data/data_to_analyse.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the electoral division data for the dublin electoral areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = pd.read_csv('data/CSO_ELECTORAL_DIVISIONS_2022_Genralised_100m_view_6971988586885511935.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs = ['FINGAL','DUN LAOGHAIRE/RATHDOWN','DUBLIN CITY','SOUTH DUBLIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = eds[eds['COUNTY_ENGLISH'].apply(lambda x: True if x in dubs else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = df.columns[28:]\n",
    "\n",
    "for col in colList:\n",
    "\n",
    "    pop = []\n",
    "\n",
    "    for ii, row in eds.iterrows():\n",
    "        tmp = df[df['ED_GUID']==row['ED_GUID']]\n",
    "        tmp = tmp[colList]\n",
    "        pop.append(tmp[col].sum())\n",
    "\n",
    "    eds[col]=pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the population adds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = gpd.read_file('data/dublin.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: WOOD QUAY A is not on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds['MATCH']=eds['ED_ID_STR'].apply(lambda x: str(gdf2[gdf2['OSIED_3441']==x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     321\n",
       "E      1\n",
       "Name: MATCH, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds['MATCH'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove WOOD A and WOOD B. sum the values together. then add back WOOD B into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_a = eds[eds['ED_ENGLISH']=='WOOD QUAY A']\n",
    "wood_b = eds[eds['ED_ENGLISH']=='WOOD QUAY B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/jsjxnj0j6vqbnpqy37npy5dw0000gn/T/ipykernel_84799/13027950.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wood_b[col].iloc[0]+=wood_a[col].iloc[0]\n"
     ]
    }
   ],
   "source": [
    "for col in colList:\n",
    "    wood_b[col].iloc[0]+=wood_a[col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = eds[eds['ED_ENGLISH'].apply(lambda x: True if 'WOOD Q' not in x else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = pd.concat([eds,wood_b]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure population adds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for ii, row in eds.iterrows():\n",
    "    tmp = gdf2[gdf2['ED_ID']==str(row['ED_ID_STR'])]\n",
    "    if len(tmp)!=1:\n",
    "        print('err')\n",
    "        \n",
    "        break\n",
    "    g.append(tmp['geometry'].values[0])\n",
    "\n",
    "eds['geometry']=g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning into a GeoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gpd.GeoDataFrame(eds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg['ID']=range(len(gg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geojson\n",
    "\n",
    "def get_bounding_box(geometry):\n",
    "    coords = np.array(list(geojson.utils.coords(geometry)))\n",
    "    return coords[:,0].min(), coords[:,0].max(),coords[:,1].min(), coords[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = []\n",
    "for ii, row in gg.iterrows():\n",
    "    ss = str(gg.envelope.iloc[ii])\n",
    "    cs = []\n",
    "    for item in ss.split(','):\n",
    "        item2 = item.split(' ')\n",
    "        for item in item2:\n",
    "            item = item.replace('(','')\n",
    "            item = item.replace(')','')\n",
    "            if len(item)>0 and item!='POLYGON':\n",
    "                cs.append(item)\n",
    "\n",
    "    cs = list(dict.fromkeys(cs))\n",
    "    cs.sort()\n",
    "    item = cs[1]+', '+ cs[2]+', '+ cs[0]+', '+ cs[3]\n",
    "    bbox.append(item)\n",
    "\n",
    "gg['bbox']=bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in columns for work, school and total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cols = [col for col in gg.columns if '- Work' in col][:-1]\n",
    "school_cols = [col for col in gg.columns if '- School' in col][:-1]\n",
    "total_cols = [col for col in gg.columns if '- Total' in col]\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[total_cols].sum())\n",
    "\n",
    "gg['total_pop']=pop\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[work_cols].sum())\n",
    "\n",
    "gg['work_pop']=pop\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[school_cols].sum())\n",
    "\n",
    "gg['school_pop']=pop\n",
    "\n",
    "gg['Active travel - Total']=gg['On foot - Total']+gg['Bicycle - Total']\n",
    "gg['Active travel - Work']=gg['On foot - Work']+gg['Bicycle - Work']\n",
    "gg['Active travel - School, college or childcare']=gg['On foot - School, college or childcare']+gg['Bicycle - School, college or childcare']\n",
    "\n",
    "\n",
    "for column in list(work_cols)+['Active travel - Work']:\n",
    "    gg[column+'_pct']=gg[column]/gg['work_pop']\n",
    "\n",
    "for column in list(total_cols)+['Active travel - Total']:\n",
    "    gg[column+'_pct']=gg[column]/gg['total_pop']\n",
    "\n",
    "for column in list(school_cols)+['Active travel - School, college or childcare']:\n",
    "    gg[column+'_pct']=gg[column]/gg['school_pop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_2022 = gg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046439"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_2022['total_pop'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06152962571157994"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_2022['Bicycle - Total'].sum()/gg_2022['total_pop'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same for 2016!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the 2022 SAM boundaries as geodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/SMALL_AREA_2022_Genralised_20m_view_-4176251332041431098.geojson', driver='GeoJSON')\n",
    "\n",
    "df = gpd.GeoDataFrame(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep Dublin SAM boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SA_NUTS3_NAME']=='Dublin'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read our SAM 2016 statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv('data/SAPS2016_SA2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each boundary, find the corresponding statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for ii, row in df.iterrows():\n",
    "    tmp = stats[stats['GUID']==row['SA_GUID_2016']]\n",
    "    if len(tmp)==1:\n",
    "        ids.append(tmp.index[0])\n",
    "    else:\n",
    "        print('error')\n",
    "        break\n",
    "\n",
    "df['SAP_ID']=ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in the stats associated with this ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "statlist = [\n",
    "'T1_1AGETT',\n",
    "'T11_1_FW',\n",
    "'T11_1_BIW',\n",
    "'T11_1_BUW',\n",
    "'T11_1_TDLW',\n",
    "'T11_1_MW',\n",
    "'T11_1_CDW',\n",
    "'T11_1_CPW',\n",
    "'T11_1_VW',\n",
    "'T11_1_OTHW',\n",
    "'T11_1_WMFHW',\n",
    "'T11_1_NSW',\n",
    "'T11_1_TW',\n",
    "'T11_1_FS',\n",
    "'T11_1_BIS',\n",
    "'T11_1_BUS',\n",
    "'T11_1_TDLS',\n",
    "'T11_1_MS',\n",
    "'T11_1_CDS',\n",
    "'T11_1_CPS',\n",
    "'T11_1_VS',\n",
    "'T11_1_OTHS',\n",
    "'T11_1_WMFHS',\n",
    "'T11_1_NSS',\n",
    "'T11_1_TS',\n",
    "'T11_1_FT',\n",
    "'T11_1_BIT',\n",
    "'T11_1_BUT',\n",
    "'T11_1_TDLT',\n",
    "'T11_1_MT',\n",
    "'T11_1_CDT',\n",
    "'T11_1_CPT',\n",
    "'T11_1_VT',\n",
    "'T11_1_OTHT',\n",
    "'T11_1_WMFHT',\n",
    "'T11_1_NST',]\n",
    "\n",
    "for stat in statlist:\n",
    "    df[stat]=df['SAP_ID'].apply(lambda x: stats[stat].iloc[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does population add up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430550"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['T1_1AGETT'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Finally rename columns based on glossary gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = pd.read_excel('data/Glossary_Saps_2022_270923.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = []\n",
    "for column in df.columns:\n",
    "    tmp = gl[gl['Column Names']==column]\n",
    "    if len(tmp)==1:\n",
    "        cc.append(tmp['Description of Field'].values[0])\n",
    "    else:\n",
    "        if 'T11_' in column:\n",
    "            tmp = gl[gl['Column Names']==column+'CCC']\n",
    "            if len(tmp)==1:\n",
    "                cc.append(tmp['Description of Field'].values[0])\n",
    "            else:\n",
    "                print('err')\n",
    "                break\n",
    "        else:\n",
    "            cc.append(column)\n",
    "\n",
    "df.columns=cc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the electoral division data for the dublin electoral areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = pd.read_csv('data/CSO_ELECTORAL_DIVISIONS_2022_Genralised_100m_view_6971988586885511935.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs = ['FINGAL','DUN LAOGHAIRE/RATHDOWN','DUBLIN CITY','SOUTH DUBLIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = eds[eds['COUNTY_ENGLISH'].apply(lambda x: True if x in dubs else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = df.columns[28:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in colList:\n",
    "\n",
    "    pop = []\n",
    "\n",
    "    for ii, row in eds.iterrows():\n",
    "        tmp = df[df['ED_GUID']==row['ED_GUID']]\n",
    "        tmp = tmp[colList]\n",
    "        pop.append(tmp[col].sum())\n",
    "\n",
    "    eds[col]=pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the population adds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430550"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = gpd.read_file('data/dublin.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: WOOD QUAY A is not on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds['MATCH']=eds['ED_ID_STR'].apply(lambda x: str(gdf2[gdf2['OSIED_3441']==x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     321\n",
       "E      1\n",
       "Name: MATCH, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds['MATCH'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove WOOD A and WOOD B. sum the values together. then add back WOOD B into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_a = eds[eds['ED_ENGLISH']=='WOOD QUAY A']\n",
    "wood_b = eds[eds['ED_ENGLISH']=='WOOD QUAY B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/jsjxnj0j6vqbnpqy37npy5dw0000gn/T/ipykernel_84799/13027950.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wood_b[col].iloc[0]+=wood_a[col].iloc[0]\n"
     ]
    }
   ],
   "source": [
    "for col in colList:\n",
    "    wood_b[col].iloc[0]+=wood_a[col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = eds[eds['ED_ENGLISH'].apply(lambda x: True if 'WOOD Q' not in x else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = pd.concat([eds,wood_b]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure population adds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430550"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds['Total'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now correct - let's get the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for ii, row in eds.iterrows():\n",
    "    tmp = gdf2[gdf2['ED_ID']==str(row['ED_ID_STR'])]\n",
    "    if len(tmp)!=1:\n",
    "        print('err')\n",
    "        \n",
    "        break\n",
    "    g.append(tmp['geometry'].values[0])\n",
    "\n",
    "eds['geometry']=g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning into a GeoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gpd.GeoDataFrame(eds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg['ID']=range(len(gg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geojson\n",
    "\n",
    "def get_bounding_box(geometry):\n",
    "    coords = np.array(list(geojson.utils.coords(geometry)))\n",
    "    return coords[:,0].min(), coords[:,0].max(),coords[:,1].min(), coords[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = []\n",
    "for ii, row in gg.iterrows():\n",
    "    ss = str(gg.envelope.iloc[ii])\n",
    "    cs = []\n",
    "    for item in ss.split(','):\n",
    "        item2 = item.split(' ')\n",
    "        for item in item2:\n",
    "            item = item.replace('(','')\n",
    "            item = item.replace(')','')\n",
    "            if len(item)>0 and item!='POLYGON':\n",
    "                cs.append(item)\n",
    "\n",
    "    cs = list(dict.fromkeys(cs))\n",
    "    cs.sort()\n",
    "    item = cs[1]+', '+ cs[2]+', '+ cs[0]+', '+ cs[3]\n",
    "    bbox.append(item)\n",
    "\n",
    "gg['bbox']=bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cols = [col for col in gg.columns if '- Work' in col][:-1]\n",
    "school_cols = [col for col in gg.columns if '- School' in col][:-1]\n",
    "total_cols = [col for col in gg.columns if '- Total' in col]\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[total_cols].sum())\n",
    "\n",
    "gg['total_pop']=pop\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[work_cols].sum())\n",
    "\n",
    "gg['work_pop']=pop\n",
    "\n",
    "pop = []\n",
    "for ii, row in gg.iterrows():\n",
    "    pop.append(row[school_cols].sum())\n",
    "\n",
    "gg['school_pop']=pop\n",
    "\n",
    "gg['Active travel - Total']=gg['On foot - Total']+gg['Bicycle - Total']\n",
    "gg['Active travel - Work']=gg['On foot - Work']+gg['Bicycle - Work']\n",
    "gg['Active travel - School, college or childcare']=gg['On foot - School, college or childcare']+gg['Bicycle - School, college or childcare']\n",
    "\n",
    "\n",
    "for column in list(work_cols)+['Active travel - Work']:\n",
    "    gg[column+'_pct']=gg[column]/gg['work_pop']\n",
    "\n",
    "for column in list(total_cols)+['Active travel - Total']:\n",
    "    gg[column+'_pct']=gg[column]/gg['total_pop']\n",
    "\n",
    "for column in list(school_cols)+['Active travel - School, college or childcare']:\n",
    "    gg[column+'_pct']=gg[column]/gg['school_pop']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now add 2016 data to main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = work_cols + school_cols + total_cols + list(gg.columns[-39:]) + ['work_pop','total_pop','school_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_delta = gg_2022[columns_to_add]-gg[columns_to_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [col for col in gg_delta.columns if 'On foot - Total' in col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_16 = gg[columns_to_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [x + '_16' for x in gg_16.columns]\n",
    "\n",
    "gg_16.columns = final_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add our delta columns which represents the change in each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "newg = pd.concat([gg_2022,gg_16],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_columns = ['delta_'+x for x in gg_delta.columns]\n",
    "\n",
    "gg_delta.columns = delta_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "newg = pd.concat([newg,gg_delta],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "newg.to_file(\"data/census_data_total.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On foot - Work\n",
      "Bicycle - Work\n",
      "Bus, minibus or coach - Work\n",
      "Train, DART or LUAS - Work\n",
      "Motorcycle or scooter - Work\n",
      "Car driver - Work\n",
      "Car passenger - Work\n",
      "Van - Work\n",
      "Other (incl. lorry) - Work\n",
      "Work mainly at or from home - Work\n",
      "Not stated - Work\n",
      "Active travel - Work\n",
      "On foot - Total\n",
      "Bicycle - Total\n",
      "Bus, minibus or coach - Total\n",
      "Train, DART or LUAS - Total\n",
      "Motorcycle or scooter - Total\n",
      "Car driver - Total\n",
      "Car passenger - Total\n",
      "Van - Total\n",
      "Other (incl. lorry) - Total\n",
      "Work mainly at or from home - Total\n",
      "Not stated - Total\n",
      "Active travel - Total\n",
      "On foot - School, college or childcare\n",
      "Bicycle - School, college or childcare\n",
      "Bus, minibus or coach - School, college or childcare\n",
      "Train, DART or LUAS - School, college or childcare\n",
      "Motorcycle or scooter - School, college or childcare\n",
      "Car driver - School, college or childcare\n",
      "Car passenger - School, college or childcare\n",
      "Van - School, college or childcare\n",
      "Other (incl. lorry) - School, college or childcare\n",
      "Work mainly at or from home - School, college or childcare\n",
      "Not stated - School, college or childcare\n",
      "Active travel - School, college or childcare\n",
      "On foot - Work_16\n",
      "Bicycle - Work_16\n",
      "Bus, minibus or coach - Work_16\n",
      "Train, DART or LUAS - Work_16\n",
      "Motorcycle or scooter - Work_16\n",
      "Car driver - Work_16\n",
      "Car passenger - Work_16\n",
      "Van - Work_16\n",
      "Other (incl. lorry) - Work_16\n",
      "Work mainly at or from home - Work_16\n",
      "Not stated - Work_16\n",
      "Active travel - Work_16\n",
      "On foot - Total_16\n",
      "Bicycle - Total_16\n",
      "Bus, minibus or coach - Total_16\n",
      "Train, DART or LUAS - Total_16\n",
      "Motorcycle or scooter - Total_16\n",
      "Car driver - Total_16\n",
      "Car passenger - Total_16\n",
      "Van - Total_16\n",
      "Other (incl. lorry) - Total_16\n",
      "Work mainly at or from home - Total_16\n",
      "Not stated - Total_16\n",
      "Active travel - Total_16\n",
      "On foot - School, college or childcare_16\n",
      "Bicycle - School, college or childcare_16\n",
      "Bus, minibus or coach - School, college or childcare_16\n",
      "Train, DART or LUAS - School, college or childcare_16\n",
      "Motorcycle or scooter - School, college or childcare_16\n",
      "Car driver - School, college or childcare_16\n",
      "Car passenger - School, college or childcare_16\n",
      "Van - School, college or childcare_16\n",
      "Other (incl. lorry) - School, college or childcare_16\n",
      "Work mainly at or from home - School, college or childcare_16\n",
      "Not stated - School, college or childcare_16\n",
      "Active travel - School, college or childcare_16\n",
      "delta_On foot - Work\n",
      "delta_Bicycle - Work\n",
      "delta_Bus, minibus or coach - Work\n",
      "delta_Train, DART or LUAS - Work\n",
      "delta_Motorcycle or scooter - Work\n",
      "delta_Car driver - Work\n",
      "delta_Car passenger - Work\n",
      "delta_Van - Work\n",
      "delta_Other (incl. lorry) - Work\n",
      "delta_Work mainly at or from home - Work\n",
      "delta_Not stated - Work\n",
      "delta_Active travel - Work\n",
      "delta_On foot - Total\n",
      "delta_Bicycle - Total\n",
      "delta_Bus, minibus or coach - Total\n",
      "delta_Train, DART or LUAS - Total\n",
      "delta_Motorcycle or scooter - Total\n",
      "delta_Car driver - Total\n",
      "delta_Car passenger - Total\n",
      "delta_Van - Total\n",
      "delta_Other (incl. lorry) - Total\n",
      "delta_Work mainly at or from home - Total\n",
      "delta_Not stated - Total\n",
      "delta_Active travel - Total\n",
      "delta_On foot - School, college or childcare\n",
      "delta_Bicycle - School, college or childcare\n",
      "delta_Bus, minibus or coach - School, college or childcare\n",
      "delta_Train, DART or LUAS - School, college or childcare\n",
      "delta_Motorcycle or scooter - School, college or childcare\n",
      "delta_Car driver - School, college or childcare\n",
      "delta_Car passenger - School, college or childcare\n",
      "delta_Van - School, college or childcare\n",
      "delta_Other (incl. lorry) - School, college or childcare\n",
      "delta_Work mainly at or from home - School, college or childcare\n",
      "delta_Not stated - School, college or childcare\n",
      "delta_Active travel - School, college or childcare\n"
     ]
    }
   ],
   "source": [
    "s= []\n",
    "for col in newg.columns:\n",
    "    if '_pct' not in col:\n",
    "        try:\n",
    "            s.append(newg[col].sum())\n",
    "        except:\n",
    "            s.append('')\n",
    "    else:\n",
    "        p = col.replace('_pct','')\n",
    "        \n",
    "        yearstring = ''\n",
    "        if '16' in p:\n",
    "            yearstring = '_16'\n",
    "\n",
    "        modestring = 'work_pop'\n",
    "        if 'School' in p:\n",
    "            modestring = 'school_pop'\n",
    "        if 'Total' in p:\n",
    "             modestring = 'total_pop'\n",
    "\n",
    "        modestring += yearstring\n",
    "        test = newg[p].sum()/newg[modestring].sum()\n",
    "\n",
    "        s.append(test)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = pd.DataFrame({'values':s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums['col']=newg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=sums.rename(columns=sums.iloc[1]).drop(sums.index[1]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums[sums.columns[13:]]\n",
    "\n",
    "sums.drop(['MATCH','geometry','ID','bbox'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [col for col in sums.columns if 'On foot - Total' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_pct = [col for col in sums.columns if 'delta' in col and '_pct' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in delta_pct:\n",
    "    v1 = col.replace('delta_','')\n",
    "    v2 = v1+'_16'\n",
    "    v3 = sums[v1].values[0]-sums[v2].values[0]\n",
    "    sums[col].iloc[0]=v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums.to_json('data/sums.json',orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
